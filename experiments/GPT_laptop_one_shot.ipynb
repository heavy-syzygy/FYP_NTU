{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "from json import loads\n",
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Setup OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Setup logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)s | %(levelname)s | %(message)s\", level=logging.INFO)\n",
    "\n",
    "# Update sys.path (or use PYTHONPATH)\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/input/laptop_quad_test_input.csv\")\n",
    "df=df.dropna(subset=[\"text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixJSON(jsonStr):\n",
    "    try:\n",
    "        jsonStr = re.sub(r'\\\\', '', jsonStr)\n",
    "\n",
    "        jsonStr = re.sub(r'{\"', '{\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'{ \"', '{\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\"}', '\\\"}', jsonStr)\n",
    "        jsonStr = re.sub(r'\" }', '\\\"}', jsonStr)\n",
    "\n",
    "        jsonStr = re.sub(r'\":\"', '\\\":\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\" : \"', '\\\":\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\":', '\\\":', jsonStr)\n",
    "        jsonStr = re.sub(r'\" :', '\\\":', jsonStr)\n",
    "        jsonStr = re.sub(r':\"', ':\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r': \"', ':\\\"', jsonStr)\n",
    "\n",
    "        jsonStr = re.sub(r'\",\"', '\\\",\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\" , \"', '\\\",\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\",', '\\\",', jsonStr)\n",
    "        jsonStr = re.sub(r'\" ,', '\\\",', jsonStr)\n",
    "        jsonStr = re.sub(r',\"', ',\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r', \"', ',\\\"', jsonStr)\n",
    "\n",
    "        jsonStr = re.sub(r'\\[\"', '\\[\\\"', jsonStr)\n",
    "        jsonStr = re.sub(r'\"\\]', '\\\"\\]', jsonStr)\n",
    "\n",
    "        split_1 = jsonStr.split('[')\n",
    "        split_1 = '['+split_1[1]\n",
    "#         print(split_1)\n",
    "        split_2 = split_1.split(']')\n",
    "        split_2 = split_2[0]+']'\n",
    "\n",
    "        jsonStr = split_2\n",
    "        \n",
    "        print(loads(jsonStr))\n",
    "        \n",
    "        return loads(jsonStr)\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from textwrap import dedent\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "ABSA_PROMPT = dedent(\n",
    "    f\"\"\"\n",
    "    Please extract aspect categories, aspect terms, related segments and related sentiments from the following text and format output in JSON:\n",
    "\n",
    "    This laptop is lightweight and has a decent keyboard but it has a slow processor.\n",
    "\n",
    "    [\n",
    "      {{ \"category\": \"Design_Features\", aspect\": \"Laptop\", \"segment\": \"This laptop is lightweight, \"sentiment\": \"positive\" }},\n",
    "      {{ \"category\": \"General\", \"aspect\": \"Keyboard\", \"segment\": \"has a decent keyboard\", \"sentiment\": \"neutral\" }},\n",
    "      {{ \"category\": \"Operation_Performance\", \"aspect\": \"CPU\", \"segment\": \"it has a slow processor\", \"sentiment\": \"negative\" }}\n",
    "    ]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ABSA_PROMPT = dedent(\n",
    "#     f\"\"\"\n",
    "#     Please extract aspect categories, aspect terms, related segments and related sentiments from the following text and format output in JSON:\n",
    "\n",
    "#     The menu has small variety of food. The drinks are quite good though, so the restaurant is not that bad but not special either.\n",
    "\n",
    "#     [\n",
    "#       {{ \"category\": \"Style_Options\", aspect\": \"Food\", \"segment\": \"The menu has small variety of food, \"sentiment\": \"negative\" }},\n",
    "#       {{ \"category\": \"Quality\", \"aspect\": \"Drinks\", \"segment\": \"The drinks are quite good\", \"sentiment\": \"positive\" }},\n",
    "#       {{ \"category\": \"General\", \"aspect\": \"Restaurant\", \"segment\": \"the restaurant is not that bad but not special either\", \"sentiment\": \"neutral\" }}\n",
    "#     ]\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "def analyze(\n",
    "    text,\n",
    "    prompt_text=ABSA_PROMPT,\n",
    "    extra_prompt=\"\",\n",
    "    temperature=0.5,\n",
    "#     max_tokens=128,\n",
    "    max_tokens=2048,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    prompt = f\"{prompt_text}\\n{extra_prompt}\\n{text}\"\n",
    "\n",
    "    return openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_results = []\n",
    "extra_prompts = []\n",
    "\n",
    "logging.getLogger(\"openai\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Analyzing reviews\"):\n",
    "    text = df.loc[i, \"text\"]\n",
    "\n",
    "    log.info(f\"Analyzing feedback - \\nText: {text}\\n\")\n",
    "\n",
    "    extra_prompt = choice(extra_prompts) if extra_prompts else \"\"\n",
    "\n",
    "    res = analyze(\n",
    "        text=text,\n",
    "        extra_prompt=\"\",\n",
    "#         max_tokens=1024,\n",
    "        temperature=0.1,\n",
    "        top_p=1,\n",
    "    )\n",
    "\n",
    "    raw_json = res[\"choices\"][0][\"text\"].strip()\n",
    "#     print(res[\"choices\"][0][\"text\"])\n",
    "#     print(raw_json)\n",
    "    try:\n",
    "        json_data = loads(raw_json)\n",
    "        analysis_results.append(json_data)\n",
    "        log.debug(f\"JSON response: {pprint(json_data)}\")\n",
    "        extra_prompts.append(f\"\\n{text}\\n{raw_json}\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"Failed to parse '{raw_json}' -> {e}\")\n",
    "        analysis_results.append(fixJSON(raw_json))\n",
    "        \n",
    "df[\"analysis\"] = analysis_results\n",
    "df.to_csv(\"./data/output/laptop/laptop_out_exp2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-formatting output data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/output/laptop/laptop_out_exp2.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df.analysis = df.analysis.apply(literal_eval)\n",
    "\n",
    "analysis_results = df.analysis\n",
    "\n",
    "analysis_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "for i, entry in enumerate(analysis_results):\n",
    "    for a in entry:\n",
    "        a[\"review_id\"] = i\n",
    "        annotations.append(a)\n",
    "\n",
    "analysis_df = pd.DataFrame(annotations)\n",
    "\n",
    "analysis_df.to_csv(\"./data/output/laptop/laptop_analysis_exp2.csv\", index=False)\n",
    "\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample n feedbacks\n",
    "df_sample = analysis_df.sample(n=10).reset_index()\n",
    "\n",
    "df_sample.to_csv(\"./data/output/laptop/laptop_analysis_sample_exp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(analysis):\n",
    "    term = []\n",
    "    pol = []\n",
    "    seg = []\n",
    "    cat = []\n",
    "    for i in analysis:\n",
    "        term.append(i[\"aspect\"])\n",
    "        cat.append(i[\"category\"])\n",
    "        pol.append(i[\"sentiment\"])\n",
    "        seg.append(i[\"segment\"])\n",
    "    return pd.Series([term, cat, pol, seg])\n",
    "df[[\"term\", \"cat\", \"pol\", \"seg\"]] = df.apply(lambda x: format_output(x[\"analysis\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "def change_sentiment_labels(data):\n",
    "    pol_list = []\n",
    "    for i in data:\n",
    "        if i == \"negative\":\n",
    "            pol_list.append(0)\n",
    "        elif i == \"neutral\":\n",
    "            pol_list.append(1)\n",
    "        elif i == \"positive\":\n",
    "            pol_list.append(2)\n",
    "    return pol_list\n",
    "df_temp['pol']=df_temp['pol'].apply(lambda x: change_sentiment_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"./data/output/laptop/laptop_out_final_exp2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_term = []\n",
    "list_pol = []\n",
    "list_cat = []\n",
    "\n",
    "def terms_pol(term, cat, pol):\n",
    "    for i in range(0, len(term)):\n",
    "        list_term.append(term[i])\n",
    "        list_cat.append(cat[i])\n",
    "        list_pol.append(pol[i])\n",
    "_ = df.apply(lambda x: terms_pol(x[\"term\"], x[\"cat\"], x[\"pol\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'terms': list_term, 'cat': list_cat, 'pol': list_pol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['terms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t = df2.groupby('terms').pol.value_counts()\n",
    "df_cat = df2.groupby(['cat','pol']).size().reset_index(name='counts')\n",
    "df_terms = df2.groupby(['terms','pol']).size().reset_index(name='counts')\n",
    "df_terms_cat = df2.groupby(['cat','terms']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_terms_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_terms_cat.sort_values(by=['counts'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_terms_cat.groupby([\"cat\", \"terms\"])[\"counts\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = df2.value_counts(normalize=True).sort_index()\n",
    "sb.countplot(x=df2['cat'])\n",
    "plt.xticks(rotation=45, \n",
    "           horizontalalignment='right',\n",
    "           fontweight='light',\n",
    "           fontsize='x-large')\n",
    "plt.show()\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = df2.value_counts(normalize=True).sort_index()\n",
    "sb.countplot(x=df2['terms'])\n",
    "plt.xticks(rotation=45, \n",
    "           horizontalalignment='right',\n",
    "           fontweight='light',\n",
    "           fontsize='x-large')\n",
    "plt.show()\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_cat,\n",
    "    x=\"cat\",\n",
    "    y=\"counts\",\n",
    "    color=\"pol\",\n",
    "    barmode=\"stack\",\n",
    "    color_discrete_map={\n",
    "        \"positive\": \"#52AC5E\",\n",
    "        \"negative\": \"#e34a2d\",\n",
    "        \"neutral\": \"gray\",\n",
    "    },\n",
    "    title=\"Categories vs Polarity\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_terms,\n",
    "    x=\"terms\",\n",
    "    y=\"counts\",\n",
    "    color=\"pol\",\n",
    "    barmode=\"stack\",\n",
    "    color_discrete_map={\n",
    "        \"positive\": \"#52AC5E\",\n",
    "        \"negative\": \"#e34a2d\",\n",
    "        \"neutral\": \"gray\",\n",
    "    },\n",
    "    title=\"Aspect Terms vs Polarity\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_terms_cat,\n",
    "    x=\"cat\",\n",
    "    y=\"counts\",\n",
    "    color=\"terms\",\n",
    "    barmode=\"stack\",\n",
    "    color_discrete_map={\n",
    "        \"positive\": \"#52AC5E\",\n",
    "        \"negative\": \"#e34a2d\",\n",
    "        \"neutral\": \"gray\",\n",
    "    },\n",
    "    title=\"Categories vs Aspect Terms\",\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_cat, values='counts', names='cat', title='Categories Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_terms, values='counts', names='terms', title='Terms Count')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# stop_words.update([\"laptop\", \"computer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(category for category in df2.loc[df2['pol']==\"positive\", \"cat\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(category for category in df2.loc[df2['pol']==\"negative\", \"cat\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(category for category in df2.loc[df2['pol']==\"neutral\", \"cat\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(term for term in df2.loc[df2['pol']==\"positive\",\"terms\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(term for term in df2.loc[df2['pol']==\"negative\",\"terms\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one review:\n",
    "text = \" \".join(term for term in df2.loc[df2['pol']==\"neutral\",\"terms\"])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(max_words=100, stopwords=stop_words).generate(text)\n",
    "wordcloud = WordCloud(max_words=100).generate(text)\n",
    "# max_font_size=50, background_color=\"white\"\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig1 = go.Figure(data=[go.Pie(labels=df_cat.pol, values=df_cat.counts, hole=.3, title='Polarity Count')])\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=2, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"positive\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"positive\",'counts'], \n",
    "                      name=\"pos\"), 1, 1) #scalegroup='on',\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"neutral\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"neutral\",'counts'], \n",
    "                     name=\"neu\"), 2, 1) #scalegroup='on',\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"negative\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"negative\",'counts'], \n",
    "                     name=\"neg\"), 1, 2) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_cat['pol'], \n",
    "                     values=df_cat['counts'], \n",
    "                     name=\"pol\"), 2, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.3, hoverinfo=\"label+percent+name\")\n",
    "fig.update_layout(margin=dict(t=0, b=0, l=0, r=0))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=2, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"positive\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"positive\",'counts'], \n",
    "                     name=\"pos\"), 1, 1) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"neutral\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"neutral\",'counts'], \n",
    "                     name=\"neu\"), 2, 1) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"negative\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"negative\",'counts'], \n",
    "                     name=\"neg\"), 1, 2) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms['pol'], \n",
    "                     values=df_terms['counts'], \n",
    "                     name=\"pol\"), 2, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n",
    "fig.update_layout(margin=dict(t=0, b=0, l=0, r=0))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_terms_cat['cat'], \n",
    "                     values=df_terms_cat['counts'], \n",
    "                     name=\"category\"), 1, 1)\n",
    "fig.add_trace(go.Pie(labels=df_terms_cat['terms'], \n",
    "                     values=df_terms_cat['counts'], \n",
    "                     name=\"term\"), 1, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n",
    "fig.update_layout(margin=dict(t=0, b=0, l=0, r=0))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cat.loc[df_cat['counts'] < 20, 'cat'] = 'Others' # Represent less frequently observerd terms\n",
    "fig = px.pie(df_cat, values='counts', names='cat', title='Categories Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_terms.loc[df_terms['counts'] < 20, 'terms'] = 'Others' # Represent less frequently observerd terms\n",
    "fig = px.pie(df_terms, values='counts', names='terms', title='Terms Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=2, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"positive\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"positive\",'counts'], \n",
    "                      name=\"pos\"), 1, 1) #scalegroup='on',\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"neutral\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"neutral\",'counts'], \n",
    "                     name=\"neu\"), 2, 1) #scalegroup='on',\n",
    "fig.add_trace(go.Pie(labels=df_cat.loc[df_cat['pol']==\"negative\",'cat'], \n",
    "                     values=df_cat.loc[df_cat['pol']==\"negative\",'counts'], \n",
    "                     name=\"neg\"), 1, 2) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_cat['pol'], \n",
    "                     values=df_cat['counts'], \n",
    "                     name=\"pol\"), 2, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.3, hoverinfo=\"label+percent+name\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=2, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}], [{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"positive\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"positive\",'counts'], \n",
    "                     name=\"pos\"), 1, 1) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"neutral\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"neutral\",'counts'], \n",
    "                     name=\"neu\"), 2, 1) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms.loc[df_terms['pol']==\"negative\",'terms'], \n",
    "                     values=df_terms.loc[df_terms['pol']==\"negative\",'counts'], \n",
    "                     name=\"neg\"), 1, 2) #scalegroup='on'\n",
    "fig.add_trace(go.Pie(labels=df_terms['pol'], \n",
    "                     values=df_terms['counts'], \n",
    "                     name=\"pol\"), 2, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_terms_cat['cat'], \n",
    "                     values=df_terms_cat['counts'], \n",
    "                     name=\"category\"), 1, 1)\n",
    "fig.add_trace(go.Pie(labels=df_terms_cat['terms'], \n",
    "                     values=df_terms_cat['counts'], \n",
    "                     name=\"term\"), 1, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n",
    "fig.update_layout(margin=dict(t=0, b=0, l=0, r=0))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display results in HTML\n",
    "\n",
    "This will display the annotated feedbacks in a prettier way using HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from html import escape\n",
    "\n",
    "css = \"\"\"\n",
    "<style>\n",
    "    .container {\n",
    "        background-color: #fff;\n",
    "        padding: 15px\n",
    "    }\n",
    "\n",
    "    p.feedback {\n",
    "        margin-top: 5px;\n",
    "        color: #595f6d;\n",
    "        line-height: 2\n",
    "    }\n",
    "\n",
    "    .annotation {\n",
    "        color: #777;\n",
    "        padding: 2px;\n",
    "        font-weight: bold !important;\n",
    "        border-radius: 1px;\n",
    "        border-bottom: 4px solid;\n",
    "    }\n",
    "\n",
    "    .aspect {\n",
    "        color: #6eb2e7;\n",
    "        padding-left: 10px;\n",
    "        font-size: 12px;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def ireplace(text, old, new):\n",
    "    pattern = re.compile(old, re.IGNORECASE)\n",
    "    return pattern.sub(new, text)\n",
    "\n",
    "\n",
    "html = f\"{css}\"\n",
    "\n",
    "for i, review in enumerate(df.to_dict(\"records\")):\n",
    "    text = escape(review[\"text\"])\n",
    "\n",
    "    try:\n",
    "        for ann in analysis_results[i]:\n",
    "            color = \"#2bbf6d\" if ann[\"sentiment\"] == \"positive\" else \"#cf2a43\"\n",
    "\n",
    "            text = ireplace(\n",
    "                text,\n",
    "                ann[\"segment\"],\n",
    "                f\"<span class='annotation' style='border-color: {color}'>{escape(ann['segment'])} <span class='aspect'>{ann['aspect']}<span class='category'>{'#'+ann['category']}</span></span>\",\n",
    "            )\n",
    "\n",
    "        html += f\"\"\"\n",
    "\n",
    "            <div class='container'>\n",
    "                <p class='feedback'>{text}</p>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {review['text']} {e}\")\n",
    "        continue\n",
    "\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "data = pd.read_csv(\"./data/output/laptop/laptop_out_final_exp2.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term_true'] = data['term_true'].apply(literal_eval)\n",
    "data['cat_true'] = data['cat_true'].apply(literal_eval)\n",
    "data['pol_true'] = data['pol_true'].apply(literal_eval)\n",
    "\n",
    "data['term'] = data['term'].apply(literal_eval)\n",
    "data['cat'] = data['cat'].apply(literal_eval)\n",
    "data['pol'] = data['pol'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_str(term, cat, pol):\n",
    "    list_term = []\n",
    "    list_cat = []\n",
    "    list_pol = []\n",
    "    \n",
    "    \n",
    "    # Gets the size of a and b.\n",
    "    sizeA, sizeB, sizeC = len(term), len(cat), len(pol)\n",
    "\n",
    "    # print(max([sizeA, sizeB, sizeC]))\n",
    "    big = max(enumerate([sizeA, sizeB, sizeC]),key=lambda x: x[1])[0]\n",
    "\n",
    "    if big == 0:\n",
    "        zeros = ['nil' for _ in range(abs(sizeA-sizeB))]\n",
    "        zeros1 = ['nil' for _ in range(abs(sizeA-sizeC))]\n",
    "        cat += zeros\n",
    "        pol += zeros1\n",
    "    elif big == 1:\n",
    "        zeros = ['nil' for _ in range(abs(sizeA-sizeB))]\n",
    "        zeros1 = ['nil' for _ in range(abs(sizeB-sizeC))]\n",
    "        term += zeros\n",
    "        pol += zeros1\n",
    "    elif big == 2:\n",
    "        zeros = ['nil' for _ in range(abs(sizeA-sizeC))]\n",
    "        zeros1 = ['nil' for _ in range(abs(sizeB-sizeC))]\n",
    "        term += zeros\n",
    "        cat += zeros1\n",
    "        \n",
    "    for i in range(0, len(term)):\n",
    "        list_term.append(str(term[i]).lower())\n",
    "        list_cat.append(str(cat[i]).lower())\n",
    "        list_pol.append(str(pol[i]).lower())\n",
    "    return pd.Series([list_term, list_cat, list_pol])\n",
    "data[[\"term_true\",\"cat_true\",\"pol_true\"]] = data.apply(lambda x: convert_lower_str(x[\"term_true\"], x[\"cat_true\"], x[\"pol_true\"]), axis=1)\n",
    "data[[\"term\",\"cat\",\"pol\"]]= data.apply(lambda x: convert_lower_str(x[\"term\"], x[\"cat\"], x[\"pol\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terms_pol(term, cat, pol):\n",
    "    list_temp = []\n",
    "    for i in range(0, len(term)):\n",
    "        list_temp.append([str(term[i]).lower(), str(cat[i]).lower(), str(pol[i]).lower()])\n",
    "    return list_temp\n",
    "data[\"True\"]= data.apply(lambda x: terms_pol(x[\"term_true\"], x[\"cat_true\"], x[\"pol_true\"]), axis=1)\n",
    "data[\"Pred\"]= data.apply(lambda x: terms_pol(x[\"term\"], x[\"cat\"], x[\"pol\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare(list1, list2):\n",
    "#     for val in list1:\n",
    "#         if val in list2:\n",
    "#             return 1\n",
    "#     return 0\n",
    "def compare_all(list1, list2):\n",
    "    if len(list1)==len(list2):\n",
    "        if all([item in list1 for item in list2]):\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"All_Matched\"]= data.apply(lambda x: compare_all(x[\"True\"], x[\"Pred\"]), axis=1)\n",
    "data[\"T_All_Matched\"]= data.apply(lambda x: compare_all(x[\"term_true\"], x[\"term\"]), axis=1)\n",
    "data[\"C_All_Matched\"]= data.apply(lambda x: compare_all(x[\"cat_true\"], x[\"cat\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of sentences: \", data.shape[0])\n",
    "print(\"Acc of aspect term  %: \", (data[\"T_All_Matched\"].sum()/data.shape[0])*100)\n",
    "print(\"Acc of aspect category  %: \", (data[\"C_All_Matched\"].sum()/data.shape[0])*100)\n",
    "print(\"Overall acc %: \", (data[\"All_Matched\"].sum()/data.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "67b579c5e5e2d0fb46ec1379fbeca811ed4f1aa8f17eceec61a0c644d552daf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
